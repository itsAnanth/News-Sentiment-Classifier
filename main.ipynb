{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oRaZnM_S8fWP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col, trim, lower\n",
        "\n",
        "spark = SparkSession.builder.appName(\"NewsSentimentAnalysis\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "def load_df():\n",
        "    uploaded = files.upload()\n",
        "    df = pd.read_csv(next(iter(uploaded)), encoding='latin1')\n",
        "    df = df[[\"text\", \"sentiment\"]]  #cloumn name as in the\n",
        "    spark_df = spark.createDataFrame(df)\n",
        "    # More robust cleaning of sentiment column\n",
        "    spark_df = spark_df.withColumn(\"sentiment\", trim(lower(col(\"sentiment\"))))\n",
        "    spark_df = spark_df.filter(\n",
        "        (col(\"sentiment\").isNotNull()) &\n",
        "        (col(\"sentiment\") != \"\") &\n",
        "        (col(\"sentiment\") != \"nan\")\n",
        "    )\n",
        "    spark_df = spark_df.filter(\n",
        "        (col(\"sentiment\") == \"positive\") | (col(\"sentiment\") == \"negative\")\n",
        "    )\n",
        "    spark_df.show()\n",
        "    return spark_df"
      ],
      "metadata": {
        "id": "CptsapinJv6g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = load_df()\n",
        "test_df = load_df()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eBu4H7oP8gS6",
        "outputId": "4db4b392-e208-4124-e79d-b24f969bb1fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0da0ea78-a46f-424f-b233-443e77736c9a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0da0ea78-a46f-424f-b233-443e77736c9a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.csv to train (2).csv\n",
            "+--------------------+---------+\n",
            "|                text|sentiment|\n",
            "+--------------------+---------+\n",
            "| Sooo SAD I will ...| negative|\n",
            "|my boss is bullyi...| negative|\n",
            "| what interview! ...| negative|\n",
            "| Sons of ****, wh...| negative|\n",
            "|2am feedings for ...| positive|\n",
            "| Journey!? Wow......| positive|\n",
            "|I really really l...| positive|\n",
            "|My Sharpie is run...| negative|\n",
            "|i want to go to m...| negative|\n",
            "|Uh oh, I am sunbu...| negative|\n",
            "| S`ok, trying to ...| negative|\n",
            "|i`ve been sick fo...| negative|\n",
            "|is back home now ...| negative|\n",
            "|Playing Ghost Onl...| positive|\n",
            "|the free fillin` ...| positive|\n",
            "|          I`m sorry.| negative|\n",
            "|On the way to Mal...| negative|\n",
            "|juss came backk f...| positive|\n",
            "|Went to sleep and...| negative|\n",
            "|I`m going home no...| positive|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b889efd7-4864-40c3-b005-bc14e3afdc37\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b889efd7-4864-40c3-b005-bc14e3afdc37\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.csv to test (2).csv\n",
            "+--------------------+---------+\n",
            "|                text|sentiment|\n",
            "+--------------------+---------+\n",
            "| Shanghai is also...| positive|\n",
            "|Recession hit Ver...| negative|\n",
            "|         happy bday!| positive|\n",
            "| http://twitpic.c...| positive|\n",
            "| that`s great!! w...| positive|\n",
            "|I THINK EVERYONE ...| negative|\n",
            "| soooooo wish i c...| negative|\n",
            "|My bike was put o...| negative|\n",
            "|I`m in VA for the...| negative|\n",
            "|Its coming out th...| negative|\n",
            "|So hot today =_= ...| negative|\n",
            "|            Miss you| negative|\n",
            "|        Cramps . . .| negative|\n",
            "| you guys didn`t ...| positive|\n",
            "|Stupid storm. No ...| negative|\n",
            "|My dead grandpa p...| negative|\n",
            "|... need retail t...| negative|\n",
            "| you are lame  go...| negative|\n",
            "|       thats so cool| positive|\n",
            "| look who I found...| positive|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.count(), test_df.count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36UJx7n1-4nk",
        "outputId": "24a52254-473d-47d8-8a68-83b6f1ccac9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16363, 2104)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.groupBy(\"sentiment\").count().show()\n",
        "test_df.groupBy(\"sentiment\").count().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnCV7xs6G7CI",
        "outputId": "19cd2276-5bea-4cbc-d44f-d3abd76c532f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|sentiment|count|\n",
            "+---------+-----+\n",
            "| positive| 8582|\n",
            "| negative| 7781|\n",
            "+---------+-----+\n",
            "\n",
            "+---------+-----+\n",
            "|sentiment|count|\n",
            "+---------+-----+\n",
            "| positive| 1103|\n",
            "| negative| 1001|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64cf68f0",
        "outputId": "86cd996e-db88-4282-848d-ae51fbec50a7"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import Word2Vec\n",
        "\n",
        "\n",
        "\n",
        "# Build ML Pipeline\n",
        "print(f\"Training samples: {train_df.count()}, Test: {test_df.count()}\")\n",
        "\n",
        "# Build improved pipeline\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=2000)  # Increased\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "labelIndexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"indexedLabel\").setHandleInvalid(\"skip\")\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.1, featuresCol=\"features\", labelCol=\"indexedLabel\")  # Tuned\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, labelIndexer, lr])\n",
        "\n",
        "# Train model using the existing train_df\n",
        "model = pipeline.fit(train_df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 16363, Test: 2104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "def evaluate(test_df):\n",
        "    print(f\"evaluation df with rows: {test_df.count()}\")\n",
        "    predictions = model.transform(test_df)\n",
        "\n",
        "    predictions.select('text', 'probability').show()\n",
        "\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator.evaluate(predictions)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Optionally compute F1-score\n",
        "    f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "    f1 = f1_evaluator.evaluate(predictions)\n",
        "    print(f\"F1-score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "1yEdNS_NGCMl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(test_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3uHmN67Ceub",
        "outputId": "e8e124ab-f1bd-4568-bf30-09c8b5459168"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation df with rows: 2104\n",
            "+--------------------+--------------------+\n",
            "|                text|         probability|\n",
            "+--------------------+--------------------+\n",
            "| Shanghai is also...|[0.93316695997353...|\n",
            "|Recession hit Ver...|[0.26749427348193...|\n",
            "|         happy bday!|[0.76834022193378...|\n",
            "| http://twitpic.c...|[0.63226015806229...|\n",
            "| that`s great!! w...|[0.55404217667697...|\n",
            "|I THINK EVERYONE ...|[0.45991358141430...|\n",
            "| soooooo wish i c...|[0.25990075547439...|\n",
            "|My bike was put o...|[0.48170222051407...|\n",
            "|I`m in VA for the...|[0.32529340563400...|\n",
            "|Its coming out th...|[0.06289082270963...|\n",
            "|So hot today =_= ...|[0.10702940040824...|\n",
            "|            Miss you|[0.29387978869182...|\n",
            "|        Cramps . . .|[0.62230557314881...|\n",
            "| you guys didn`t ...|[0.67494332341428...|\n",
            "|Stupid storm. No ...|[0.64765724736036...|\n",
            "|My dead grandpa p...|[0.19960006523781...|\n",
            "|... need retail t...|[0.07536261418514...|\n",
            "| you are lame  go...|[0.41535526132874...|\n",
            "|       thats so cool|[0.69728494532706...|\n",
            "| look who I found...|[0.68944155659425...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Accuracy: 0.7875\n",
            "F1-score: 0.7875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBcEMRsyFcF5",
        "outputId": "e8649757-73ab-47b7-a332-cdb719351069"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation df with rows: 16363\n",
            "+--------------------+--------------------+\n",
            "|                text|         probability|\n",
            "+--------------------+--------------------+\n",
            "| Sooo SAD I will ...|[0.09433190221133...|\n",
            "|my boss is bullyi...|[0.46573050821159...|\n",
            "| what interview! ...|[0.40911909718575...|\n",
            "| Sons of ****, wh...|[0.50823170262448...|\n",
            "|2am feedings for ...|[0.81257661484290...|\n",
            "| Journey!? Wow......|[0.82171134447466...|\n",
            "|I really really l...|[0.86764598961562...|\n",
            "|My Sharpie is run...|[0.27167667389436...|\n",
            "|i want to go to m...|[0.30261777556025...|\n",
            "|Uh oh, I am sunbu...|[0.47454770797212...|\n",
            "| S`ok, trying to ...|[0.23250682550946...|\n",
            "|i`ve been sick fo...|[0.33084405362576...|\n",
            "|is back home now ...|[0.31963645369293...|\n",
            "|Playing Ghost Onl...|[0.72015270196714...|\n",
            "|the free fillin` ...|[0.66048136696424...|\n",
            "|          I`m sorry.|[0.35755840920519...|\n",
            "|On the way to Mal...|[0.48266269984661...|\n",
            "|juss came backk f...|[0.71867004301543...|\n",
            "|Went to sleep and...|[0.12943843611876...|\n",
            "|I`m going home no...|[0.71645738855301...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Accuracy: 0.8486\n",
            "F1-score: 0.8485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.write().overwrite().save(\"/content/news_sentiment_model\")"
      ],
      "metadata": {
        "id": "HISkSLhqDSAx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_KEY = 'dc4e05a01f6b41469d7feb0ab22e65ce'  # Replace with your key\n",
        "url = 'https://newsapi.org/v2/everything?q=finance&apiKey=' + API_KEY + '&pageSize=5'\n",
        "response = requests.get(url)\n",
        "print(\"Status:\", response.status_code)\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    print(\"Sample Articles:\", len(data.get('articles', [])))\n",
        "    if data.get('articles'):\n",
        "        print(\"Sample Title:\", data['articles'][0]['title'])\n",
        "else:\n",
        "    print(\"Error Details:\", response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2os_f7SSOd2",
        "outputId": "7bbabb38-1e87-4bc4-97b5-5b2b4f1ef075"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status: 200\n",
            "Sample Articles: 5\n",
            "Sample Title: Robinhood Is Building a Social Network for Following Market Movers’ Trades\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import when, col, udf\n",
        "from pyspark.ml import PipelineModel\n",
        "import plotly.express as px\n",
        "import requests\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
        "from pyspark.ml.linalg import DenseVector\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder.appName(\"Dashboard\").getOrCreate()\n",
        "model = PipelineModel.load(\"/content/news_sentiment_model\")\n",
        "\n",
        "# Fetch function with debugging\n",
        "def fetch_news_headlines(query='finance', num_articles=20):\n",
        "    API_KEY = 'dc4e05a01f6b41469d7feb0ab22e65ce'  # Replace with your NewsAPI key\n",
        "    url = 'https://newsapi.org/v2/everything'\n",
        "    params = {'q': query, 'apiKey': API_KEY, 'sortBy': 'publishedAt', 'pageSize': num_articles}\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        st.write(\"API Response Status:\", response.status_code)\n",
        "        if 'articles' not in data or not data['articles']:\n",
        "            st.error(\"No articles found. Try broader query like 'news'.\")\n",
        "            return pd.DataFrame()\n",
        "        headlines = []\n",
        "        for article in data['articles']:\n",
        "            if article.get('title'):\n",
        "                headlines.append({\n",
        "                    'title': article['title'],\n",
        "                    'source': article.get('source', {}).get('name', 'Unknown'),\n",
        "                    'publishedAt': article.get('publishedAt', '')\n",
        "                })\n",
        "        if not headlines:\n",
        "            st.error(\"No valid titles extracted.\")\n",
        "            return pd.DataFrame()\n",
        "        df = pd.DataFrame(headlines)\n",
        "        st.write(\"Fetched Headlines:\", df.head())  # Debug: Show fetched data\n",
        "        return df\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        st.error(f\"API Request Failed: {e}\")\n",
        "        return pd.DataFrame()\n",
        "    except ValueError as e:\n",
        "        st.error(f\"JSON Decode Error: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# UDF to extract positive and negative probabilities\n",
        "extract_pos_prob = udf(lambda v: float(v[1]) if v is not None else 0.0, \"double\")\n",
        "extract_neg_prob = udf(lambda v: float(v[0]) if v is not None else 0.0, \"double\")\n",
        "\n",
        "# Predict function (using both probabilities)\n",
        "def predict_sentiment(headlines_df):\n",
        "    if headlines_df.empty or 'title' not in headlines_df.columns:\n",
        "        return pd.DataFrame(columns=['text', 'sentiment', 'probability'])\n",
        "    # Create Spark DataFrame\n",
        "    spark_df = spark.createDataFrame(headlines_df['title'], \"string\").withColumnRenamed(\"value\", \"text\")\n",
        "    # Manually apply feature extraction\n",
        "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=2000)\n",
        "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "    # Transform without fit for Tokenizer and HashingTF\n",
        "    words_data = tokenizer.transform(spark_df)\n",
        "    tf_data = hashingTF.transform(words_data)\n",
        "    idf_model = idf.fit(tf_data)\n",
        "    featured_data = idf_model.transform(tf_data)\n",
        "    # Extract the classifier and predict\n",
        "    classifier = model.stages[-1]  # LogisticRegressionModel\n",
        "    preds = classifier.transform(featured_data)\n",
        "    # Debug: Show unique prediction values\n",
        "    # st.write(\"Prediction Values:\", preds.select(\"prediction\").distinct().collect())\n",
        "    # Add extracted probabilities as columns\n",
        "    preds = preds.withColumn(\"pos_prob\", extract_pos_prob(preds[\"probability\"]))\n",
        "    preds = preds.withColumn(\"neg_prob\", extract_neg_prob(preds[\"probability\"]))\n",
        "    preds_pd = preds.select(\"text\", \"prediction\", \"probability\", \"pos_prob\", \"neg_prob\").toPandas()\n",
        "    # Debug: Show sample probabilities\n",
        "    st.write(\"Sample Probabilities:\", preds_pd[['text', 'pos_prob', 'neg_prob']].head())\n",
        "    # Adjust thresholds:\n",
        "    preds_pd['sentiment'] = preds_pd.apply(\n",
        "        lambda row: \"Positive\" if row['pos_prob'] >= row['neg_prob'] else \"Negative\",\n",
        "        axis=1\n",
        "    )\n",
        "    result = preds_pd[['text', 'sentiment', 'probability']]\n",
        "    if result.empty:\n",
        "        st.warning(\"No predictions generated—check model compatibility.\")\n",
        "    return result\n",
        "\n",
        "# Streamlit app\n",
        "st.title(\"🚀 Real-Time News Sentiment Dashboard\")\n",
        "st.markdown(\"Powered by PySpark ML – Analyzing Live News!\")\n",
        "\n",
        "query = st.sidebar.text_input(\"News Topic\", \"finance\")\n",
        "if st.sidebar.button(\"Fetch & Predict\"):\n",
        "    with st.spinner(\"Analyzing sentiments...\"):\n",
        "        news_df = fetch_news_headlines(query)\n",
        "        if not news_df.empty:\n",
        "            preds_df = predict_sentiment(news_df)\n",
        "            st.session_state.preds = preds_df\n",
        "        else:\n",
        "            st.error(\"No news fetched. Check API key or query.\")\n",
        "\n",
        "if 'preds' in st.session_state:\n",
        "    df = st.session_state.preds\n",
        "    st.subheader(\"Latest News Headlines\")\n",
        "    df['confidence'] = df['probability'].apply(lambda x: f\"{max(x)*100:.1f}%\")\n",
        "    st.dataframe(df[['text', 'sentiment', 'confidence']], use_container_width=True)\n",
        "\n",
        "    st.subheader(\"Sentiment Distribution\")\n",
        "    fig = px.pie(df, names='sentiment', title=\"Sentiment Distribution\",\n",
        "                 color='sentiment', color_discrete_map={'Positive': '#00CC96', 'Negative': '#EF553B', 'Neutral': '#AB63FA'})\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    st.subheader(\"Sentiment Bar Chart\")\n",
        "    st.bar_chart(df['sentiment'].value_counts())\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.info(f\"Data from NewsAPI.org \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkd9xelhSR8u",
        "outputId": "fd79985c-f6dc-48f7-cff3-d00b71268e51"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1R-Qb1ASXrE",
        "outputId": "4beca4be-74d3-4240-d02c-c478ebb4bd04"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.4.0-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.4.0 streamlit-1.50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2OGvdUYAA80CrlzQV3s7kENO0wq_4vtn4GDqhrpi7LfW38XSr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt-HE3CGSuZc",
        "outputId": "e6d95038-e1a8-4750-efad-3f51e439799a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok\n"
      ],
      "metadata": {
        "id": "vzupm2MyTuCw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any existing tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Start Streamlit in the background\n",
        "get_ipython().system_raw('streamlit run /content/app.py &')\n",
        "\n",
        "# Connect ngrok (explicitly set proto to http)\n",
        "public_url = ngrok.connect(addr=8501, proto=\"http\")\n",
        "print(\"🔗 Public URL:\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUbFws_XTZAg",
        "outputId": "500229b8-701c-4a16-ed3b-a9ab0a027374"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-28T08:15:51+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Public URL: NgrokTunnel: \"https://9a2ff79d5250.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r news_sentiment_model.zip news_sentiment_model/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRnwolJFTkMz",
        "outputId": "e9a0bc8a-75b9-4be4-9e27-7c4cef7affe9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: news_sentiment_model/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/0_Tokenizer_a3c2e0091d7b/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/0_Tokenizer_a3c2e0091d7b/metadata/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/0_Tokenizer_a3c2e0091d7b/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/0_Tokenizer_a3c2e0091d7b/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/0_Tokenizer_a3c2e0091d7b/metadata/_SUCCESS (stored 0%)\n",
            "  adding: news_sentiment_model/stages/0_Tokenizer_a3c2e0091d7b/metadata/part-00000 (deflated 33%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/data/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/data/._SUCCESS.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/data/part-00000-9832d494-e05e-41d5-8587-e81492ec4050-c000.snappy.parquet (deflated 37%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/data/_SUCCESS (stored 0%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/data/.part-00000-9832d494-e05e-41d5-8587-e81492ec4050-c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/metadata/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/metadata/_SUCCESS (stored 0%)\n",
            "  adding: news_sentiment_model/stages/3_StringIndexer_3e5ee1261095/metadata/part-00000 (deflated 38%)\n",
            "  adding: news_sentiment_model/stages/1_HashingTF_f6a326fcdec3/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/1_HashingTF_f6a326fcdec3/metadata/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/1_HashingTF_f6a326fcdec3/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/1_HashingTF_f6a326fcdec3/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/1_HashingTF_f6a326fcdec3/metadata/_SUCCESS (stored 0%)\n",
            "  adding: news_sentiment_model/stages/1_HashingTF_f6a326fcdec3/metadata/part-00000 (deflated 37%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/data/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/data/._SUCCESS.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/data/_SUCCESS (stored 0%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/data/.part-00000-51337cb6-bc1c-4808-a302-b25ba063fea3-c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/data/part-00000-51337cb6-bc1c-4808-a302-b25ba063fea3-c000.snappy.parquet (deflated 18%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/metadata/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/metadata/_SUCCESS (stored 0%)\n",
            "  adding: news_sentiment_model/stages/4_LogisticRegression_47edc5fc2bed/metadata/part-00000 (deflated 45%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/data/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/data/._SUCCESS.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/data/_SUCCESS (stored 0%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/data/part-00000-b2aa4c58-1712-4e90-b1fd-92b35079d95d-c000.snappy.parquet (deflated 37%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/data/.part-00000-b2aa4c58-1712-4e90-b1fd-92b35079d95d-c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/metadata/ (stored 0%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/metadata/_SUCCESS (stored 0%)\n",
            "  adding: news_sentiment_model/stages/2_IDF_9a29f9880fb7/metadata/part-00000 (deflated 32%)\n",
            "  adding: news_sentiment_model/metadata/ (stored 0%)\n",
            "  adding: news_sentiment_model/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: news_sentiment_model/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: news_sentiment_model/metadata/_SUCCESS (stored 0%)\n",
            "  adding: news_sentiment_model/metadata/part-00000 (deflated 24%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WaMJsV3CZ0LO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}